{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 背後演算法\n",
    "\n",
    "## jieba 中文斷詞所使用的演算法是基於 Trie Tree 結構去生成句子中中文字所有可能成詞的情況，然後使用動態規劃（Dynamic programming）算法來找出最大機率的路徑，這個路徑就是基於詞頻的最大斷詞結果。對於辨識新詞（字典詞庫中不存在的詞）則使用了 HMM 模型（Hidden Markov Model）及 Viterbi 算法來辨識出來。基本上這樣就可以完成具有斷詞功能的程式了，或許我之後可以找個時間寫幾篇部落格來介紹這幾個演算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型\n",
    "## jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细\n",
    "## 待分词的字符串可以是 unicode 或 UTF-8 字符串、GBK 字符串。注意：不建议直接输入 GBK 字符串，可能无法预料地错误解码成 UTF-8\n",
    "## jieba.cut 以及 jieba.cut_for_search 返回的结构都是一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语(unicode)，或者用\n",
    "## jieba.lcut 以及 jieba.lcut_for_search 直接返回 list\n",
    "## jieba.Tokenizer(dictionary=DEFAULT_DICT) 新建自定义分词器，可用于同时使用不同词典。jieba.dt 为默认分词器，所有全局分词相关函数都是该分词器的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.179 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 我/ 來/ 到/ 資/ 訊/ 策/ 進/ 會/ 學/ 習/ 資/ 料/ 分析\n",
      "Default Mode: 我來/ 到/ 資訊策/ 進會/ 學習/ 資料/ 分析\n",
      "我來, 到, 資訊策, 進會, 學習, 資料, 分析\n",
      "小明, 碩士, 畢業, 於, 中央, 大學, 計算, 實驗, 所, ，, 然後在, 日本, 京都, 大學, 深造\n"
     ]
    }
   ],
   "source": [
    "# encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"我來到資訊策進會學習資料分析\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我來到資訊策進會學習資料分析\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精確模式\n",
    "\n",
    "seg_list = jieba.cut(\"我來到資訊策進會學習資料分析\", cut_all=False,HMM=True)  # 默認是精確模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明碩士畢業於中央大學計算實驗所，然後在日本京都大學深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input： 獨立音樂需要大家一起來推廣，歡迎加入我們的行列！\n",
      "Output 精確模式 Full Mode：\n",
      "獨立/音樂/需要/大家/一起/來/推廣/，/歡迎/加入/我們/的/行列/！\n",
      "Input： 独立音乐需要大家一起来推广，欢迎加入我们的行列！\n",
      "Output 精確模式 Full Mode：\n",
      "独立/音乐/需要/大家/一/起来/推广/，/欢迎/加入/我们/的/行列/！\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "sentence = \"獨立音樂需要大家一起來推廣，歡迎加入我們的行列！\"\n",
    "print (\"Input：\", sentence)\n",
    "words = jieba.cut(sentence, cut_all=False ,HMM=True)\n",
    "print (\"Output 精確模式 Full Mode：\")\n",
    "print ('/'.join(words))\n",
    "\n",
    "sentence = \"独立音乐需要大家一起来推广，欢迎加入我们的行列！\"\n",
    "print (\"Input：\", sentence)\n",
    "words = jieba.cut(sentence, cut_all=False)\n",
    "print (\"Output 精確模式 Full Mode：\")\n",
    "print(\"/\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 精確模式 Full Mode : \n",
      "一顆/葡萄/有/多/甜美/ /用/盡/了/所有/的/ /圖騰/和/語言/ /描寫/\n",
      "/想/一個/人/有/多/想念/ /那/又/是/文字/失效/瞬間/\n",
      "/\n",
      "/結一個/紀念/的/繩結/ /記錄/你/離/去/後/ /萬語/和/千言/ /瓦解/\n",
      "/升起/了/慌/張/的/狼/煙/ /我/遺落/在/最/孤獨/史前/ /的/荒野/\n",
      "/\n",
      "/多遙遠/ /多/糾結/ /多/想念/ /多無法/描寫/ /疼痛/ /和/瘋癲/ /你/都/看/不見/\n",
      "/想/穿越/ /想/飛天/ /想/變成/ /造字/的/倉/頡/ /寫出/ /能/讓/你/快/回來/ /的/詩篇/\n",
      "/\n",
      "/一/隻/蝴蝶/有多鮮/豔/ /能/不能/飛越過/ /猜忌/和/冷漠/ /世界/\n",
      "/給你/的/簡訊/和/留言/ /說/不/清萬分/之一/追悔/\n",
      "/\n",
      "/當/星宿/都/沉/沒/山岳/ /只/盼/你/會/抬頭/ /看/我/寄/託/的/ /彎/月/\n",
      "/當一個/文明/即將/熄滅/ /有什麼/證明/你/我/存在/ /的/歲/月/\n",
      "/\n",
      "/多遙遠/ /多/糾結/ /多/想念/ /多無法/描寫/ /疼痛/ /和/瘋癲/ /你/都/看/不見/\n",
      "/想/穿越/ /想/飛天/ /想/變成/ /造字/的/倉/頡/ /創造/ /能/讓/你/想起/我/ /的/字眼/\n",
      "/\n",
      "/\n",
      "/多遙遠/ /多/糾結/ /多/想念/ /多無法/描寫/ /疼痛/ /和/瘋癲/ /你/都/看/不見/\n",
      "/想/穿越/ /想/飛天/ /想/變成/ /造字/的/倉/頡/ /寫出/ /能/讓/你/快/回來/ /的詩/\n",
      "/\n",
      "/需要/你/ /需要/你/ /需要/你/ /想逆轉/時間/ /回到/ /最開始/ /有/你/的/世界/\n",
      "/想/穿越/ /想/飛天/ /想/變成/ /造字/的/倉/頡/ /寫出/ /讓/宇宙/能/重來/ /的/詩篇/\n",
      "/\n",
      "/天雨粟/ /鬼夜/哭/ /思念/漫/太古\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "\n",
    "content = open('lyrice.txt','r').read()\n",
    "\n",
    "words = jieba.cut(content,cut_all=False)\n",
    "print(\"Output 精確模式 Full Mode : \")\n",
    "\n",
    "print(\"/\".join(words))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyrice.txt', 'r').read()\n",
    "\n",
    "print (\"Input：\", content)\n",
    "\n",
    "words = jieba.cut(content, cut_all=False)\n",
    "\n",
    "print (\"Output 精確模式 Full Mode：\")\n",
    "print(\"/\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content=open('lyric.txt','r').read()\n",
    "\n",
    "words = jieba.cut(content,cut_all=False,HMM=True)\n",
    "\n",
    "print(\"/\".join(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba 提供了一個功能讓使用者可以增加自定義詞庫，這種無法用 HMM 判斷出來的新詞就可以得到改善"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其中每一行代表一筆語料資料，首先填上自定義詞如：「袂當」、「袂記」，然後填上權重，權重值可以依照斷詞結果做自己想做的調整，最後填上詞性，但詞性非必要填寫，詞性列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行袂開跤 2 v\n",
    "袂當 4 d\n",
    "袂記 4 v\n",
    "袂有 4 d\n",
    "唱著 4 v\n",
    "每一個 4 m\n",
    "會使 70 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "jieba.load_userdict('user.txt')\n",
    "content=open('lyric.txt','r',encoding='UTF-8').read()\n",
    "\n",
    "words = jieba.cut(content,cut_all=False,HMM=True)\n",
    "\n",
    "print(\"/\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "# 取出斷詞詞性\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyrice.txt', 'r').read()\n",
    "\n",
    "words = pseg.cut(content)\n",
    "\n",
    "print (\"-------------------------------\")\n",
    "for word in words:\n",
    "    print (word.word,\"=\",word.flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 取出斷詞位置\n",
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyrice.txt', 'r').read()\n",
    "\n",
    "words = jieba.tokenize(content, 'utf-8')\n",
    "\n",
    "for tk in words:\n",
    "    print (\"word %s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.set_dictionary('dict.txt.big')\n",
    "\n",
    "content = open('lyrice.txt', 'r').read()\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, 10)\n",
    "\n",
    "print( \"/\".join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
