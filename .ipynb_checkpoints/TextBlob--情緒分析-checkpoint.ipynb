{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##可以作正負面情緒分析\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "train = [('I love this sandwich.', 'pos'),('This is an amazing place!', 'pos'),('I feel very good about these beers.', 'pos'),\n",
    "         ('I do not like this restaurant', 'neg'),('I am tired of this stuff.', 'neg'),\n",
    "         (\"I can't deal with this\", 'neg'),(\"My boss is horrible.\", \"neg\")\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "cl.classify(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.429\n",
      "             2          -0.60267        0.571\n",
      "             3          -0.54528        0.857\n",
      "             4          -0.49774        0.857\n",
      "             5          -0.45784        0.857\n",
      "             6          -0.42392        0.857\n",
      "             7          -0.39474        0.857\n",
      "             8          -0.36937        1.000\n",
      "             9          -0.34708        1.000\n",
      "            10          -0.32733        1.000\n",
      "            11          -0.30970        1.000\n",
      "            12          -0.29386        1.000\n",
      "            13          -0.27953        1.000\n",
      "            14          -0.26650        1.000\n",
      "            15          -0.25460        1.000\n",
      "            16          -0.24369        1.000\n",
      "            17          -0.23365        1.000\n",
      "            18          -0.22437        1.000\n",
      "            19          -0.21578        1.000\n",
      "            20          -0.20779        1.000\n",
      "            21          -0.20035        1.000\n",
      "            22          -0.19340        1.000\n",
      "            23          -0.18690        1.000\n",
      "            24          -0.18080        1.000\n",
      "            25          -0.17507        1.000\n",
      "            26          -0.16968        1.000\n",
      "            27          -0.16460        1.000\n",
      "            28          -0.15980        1.000\n",
      "            29          -0.15525        1.000\n",
      "            30          -0.15095        1.000\n",
      "            31          -0.14687        1.000\n",
      "            32          -0.14300        1.000\n",
      "            33          -0.13932        1.000\n",
      "            34          -0.13581        1.000\n",
      "            35          -0.13247        1.000\n",
      "            36          -0.12929        1.000\n",
      "            37          -0.12624        1.000\n",
      "            38          -0.12333        1.000\n",
      "            39          -0.12055        1.000\n",
      "            40          -0.11789        1.000\n",
      "            41          -0.11533        1.000\n",
      "            42          -0.11288        1.000\n",
      "            43          -0.11053        1.000\n",
      "            44          -0.10827        1.000\n",
      "            45          -0.10610        1.000\n",
      "            46          -0.10401        1.000\n",
      "            47          -0.10200        1.000\n",
      "            48          -0.10006        1.000\n",
      "            49          -0.09820        1.000\n",
      "            50          -0.09640        1.000\n",
      "            51          -0.09466        1.000\n",
      "            52          -0.09298        1.000\n",
      "            53          -0.09136        1.000\n",
      "            54          -0.08979        1.000\n",
      "            55          -0.08827        1.000\n",
      "            56          -0.08680        1.000\n",
      "            57          -0.08538        1.000\n",
      "            58          -0.08400        1.000\n",
      "            59          -0.08267        1.000\n",
      "            60          -0.08137        1.000\n",
      "            61          -0.08012        1.000\n",
      "            62          -0.07890        1.000\n",
      "            63          -0.07772        1.000\n",
      "            64          -0.07657        1.000\n",
      "            65          -0.07545        1.000\n",
      "            66          -0.07437        1.000\n",
      "            67          -0.07331        1.000\n",
      "            68          -0.07229        1.000\n",
      "            69          -0.07129        1.000\n",
      "            70          -0.07032        1.000\n",
      "            71          -0.06937        1.000\n",
      "            72          -0.06845        1.000\n",
      "            73          -0.06755        1.000\n",
      "            74          -0.06667        1.000\n",
      "            75          -0.06582        1.000\n",
      "            76          -0.06499        1.000\n",
      "            77          -0.06417        1.000\n",
      "            78          -0.06338        1.000\n",
      "            79          -0.06261        1.000\n",
      "            80          -0.06185        1.000\n",
      "            81          -0.06111        1.000\n",
      "            82          -0.06039        1.000\n",
      "            83          -0.05969        1.000\n",
      "            84          -0.05900        1.000\n",
      "            85          -0.05833        1.000\n",
      "            86          -0.05767        1.000\n",
      "            87          -0.05702        1.000\n",
      "            88          -0.05639        1.000\n",
      "            89          -0.05578        1.000\n",
      "            90          -0.05517        1.000\n",
      "            91          -0.05458        1.000\n",
      "            92          -0.05400        1.000\n",
      "            93          -0.05344        1.000\n",
      "            94          -0.05288        1.000\n",
      "            95          -0.05234        1.000\n",
      "            96          -0.05181        1.000\n",
      "            97          -0.05128        1.000\n",
      "            98          -0.05077        1.000\n",
      "            99          -0.05027        1.000\n",
      "         Final          -0.04978        1.000\n",
      "neg\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from textblob.classifiers import MaxEntClassifier\n",
    "train_data = [('I love this sandwich.', 'pos'),('This is an amazing place!', 'pos'),('I feel very good about these beers.', 'pos'),\n",
    "         ('I do not like this restaurant', 'neg'),('I am tired of this stuff.', 'neg'),\n",
    "         (\"I can't deal with this\", 'neg'),(\"My boss is horrible.\", \"neg\")\n",
    "]\n",
    "classifier = MaxEntClassifier(train_data)\n",
    "prob_dist = classifier.prob_classify(\"I feel happy this morning.\")\n",
    "print(prob_dist.max())\n",
    "\n",
    "print(prob_dist.prob(\"positive\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
